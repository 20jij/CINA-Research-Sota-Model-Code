{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7076e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csgraph\n",
    "from main.utils import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "267e3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch-geometric\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68b6a25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Is GPU available? {}\\n'.format(torch.cuda.is_available()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1c8c82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_gephi(dataset, gt_y, gt_x, pred_x):\n",
    "    graph = load_dataset(dataset)\n",
    "    true_G = nx.from_scipy_sparse_matrix(graph.adj_matrix)\n",
    "    pred_G = nx.from_scipy_sparse_matrix(graph.adj_matrix)\n",
    "    true_y = nx.from_scipy_sparse_matrix(graph.adj_matrix)\n",
    "    \n",
    "    for i in true_G.nodes:\n",
    "        true_G.nodes[i]['class'] = gt_x[i]\n",
    "        pred_G.nodes[i]['class'] = pred_x[i]\n",
    "        true_y.nodes[i]['inf_rate'] = gt_y[i]\n",
    "        \n",
    "    nx.write_gexf(true_G, \"{}_GCNSI_real.gexf\".format(dataset))\n",
    "    nx.write_gexf(pred_G, \"{}_GCNSI_pred.gexf\".format(dataset))\n",
    "    nx.write_gexf(true_y, \"{}_GCNSI_y.gexf\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7122e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Add self-loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Multiply with weights\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Calculate the normalization\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4: Propagate the embeddings to the next layer\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x,\n",
    "                              norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e56bba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(4, 128)\n",
    "        self.conv2 = GCNConv(128, 128)\n",
    "        self.fc =torch.nn.Linear(128,2)\n",
    "\n",
    "    def forward(self, x,edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1a8132c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'new_data/Combo_github2stack_'\n",
    "diffusion_model_proj = 'LT'\n",
    "diffusion_model_rec = 'IC'\n",
    "seed_rate = 1\n",
    "sample = 100\n",
    "dataset_file = '{}{}2{}_{}_{}.SG'.format(dataset, diffusion_model_proj,\n",
    "                                    diffusion_model_rec, str(10*seed_rate), sample)\n",
    "with open(dataset_file, 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "    \n",
    "Combined_Graph, adj, prob_matrix, inverse_pairs = graph['Combined_Graph'], graph['adj'], graph['prob'], graph['inverse_pairs']\n",
    "\n",
    "# with open('new_data/github2stack_IC2SIS_10_100.SG', 'rb') as f:\n",
    "#     graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. training of both networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86af0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.15\n",
    "# 0.05\n",
    "threshold = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d232ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj, inverse_pairs, prob = graph['adj_received'], np.array(graph['inverse_pairs_received']), graph['prob_received']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ccb71e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(inverse_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "484bac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.2\n",
      "PyTorch version: 2.1.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade numpy scipy\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cdfa2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "random_seed = 42\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Define the total number of samples\n",
    "total_samples = inverse_pairs.shape[0]\n",
    "\n",
    "# Calculate the number of samples for training and testing\n",
    "num_train_samples = int(total_samples * split_ratio)\n",
    "num_test_samples = total_samples - num_train_samples\n",
    "\n",
    "# Create a list of shuffled indices\n",
    "indices = list(range(total_samples))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use the shuffled indices to split the data\n",
    "train_indices = indices[:num_train_samples]\n",
    "test_indices = indices[num_train_samples:]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "inverse_pairs_train = inverse_pairs[train_indices]\n",
    "inverse_pairs_test = inverse_pairs[test_indices]\n",
    "\n",
    "# print(inverse_pairs)\n",
    "# print(inverse_pairs_train)\n",
    "# print(inverse_pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a766acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "S = csgraph.laplacian(adj, normed=False)\n",
    "print(type(S))\n",
    "\n",
    "# S = np.array(coo_matrix.todense(S)) REMOVED LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "958a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = adj.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f82a8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d24239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_sparse = coo_matrix(adj) # ADDED LINE\n",
    "\n",
    "coo = adj_sparse.tocoo()\n",
    "row = torch.from_numpy(coo.row.astype(np.int64)).to(torch.long).to(device)\n",
    "col = torch.from_numpy(coo.col.astype(np.int64)).to(torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b27b0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.stack([row, col], dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9af3ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion=torch.nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.5]).to(device)) #[2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7ce47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f3c55092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "loss:0.338922\n",
      "training acc: 0.5028438358516485\n",
      "training pr: 0.024557366358949624\n",
      "training re: 0.4863541666666668\n",
      "training fs: 0.028248418531810694\n",
      "training auc: 0.4426496482731417\n",
      "epoch:1\n",
      "loss:0.291237\n",
      "training acc: 0.7064453125000001\n",
      "training pr: 0.01611460145424893\n",
      "training re: 0.2730208333333334\n",
      "training fs: 0.02051761688409081\n",
      "training auc: 0.4432668412517531\n",
      "epoch:2\n",
      "loss:0.239825\n",
      "training acc: 0.4327459649725275\n",
      "training pr: 0.02667937613244345\n",
      "training re: 0.5560416666666667\n",
      "training fs: 0.03795175018063318\n",
      "training auc: 0.44670802105247764\n",
      "epoch:3\n",
      "loss:0.232420\n",
      "training acc: 0.6611650068681321\n",
      "training pr: 0.041996421739990915\n",
      "training re: 0.3135416666666667\n",
      "training fs: 0.037103557021397164\n",
      "training auc: 0.4470701572726742\n",
      "epoch:4\n",
      "loss:0.213204\n",
      "training acc: 0.18033567994505495\n",
      "training pr: 0.018992681229169132\n",
      "training re: 0.7682291666666664\n",
      "training fs: 0.036974199200733325\n",
      "training auc: 0.44604690787166934\n",
      "epoch:5\n",
      "loss:0.210009\n",
      "training acc: 0.38544814560439566\n",
      "training pr: 0.017923362925386793\n",
      "training re: 0.5312500000000002\n",
      "training fs: 0.03450283284306647\n",
      "training auc: 0.44518875642823746\n",
      "epoch:6\n",
      "loss:0.207492\n",
      "training acc: 0.12363066620879122\n",
      "training pr: 0.017918464704311445\n",
      "training re: 0.7740625\n",
      "training fs: 0.03501873019987562\n",
      "training auc: 0.4478910267648433\n",
      "epoch:7\n",
      "loss:0.206944\n",
      "training acc: 0.21733344780219782\n",
      "training pr: 0.01713310654060994\n",
      "training re: 0.6568749999999998\n",
      "training fs: 0.0333882532468935\n",
      "training auc: 0.44410896775654524\n",
      "epoch:8\n",
      "loss:0.206549\n",
      "training acc: 0.12849201579670327\n",
      "training pr: 0.017439108702475878\n",
      "training re: 0.7465625000000002\n",
      "training fs: 0.03408130220443411\n",
      "training auc: 0.443446037502922\n",
      "epoch:9\n",
      "loss:0.206204\n",
      "training acc: 0.1572802197802198\n",
      "training pr: 0.017271134896102103\n",
      "training re: 0.7137500000000001\n",
      "training fs: 0.03372570498393636\n",
      "training auc: 0.4430442817905563\n",
      "epoch:10\n",
      "loss:0.205802\n",
      "training acc: 0.12914019574175825\n",
      "training pr: 0.01745820561186022\n",
      "training re: 0.7465625\n",
      "training fs: 0.03411849585742666\n",
      "training auc: 0.444977208976157\n",
      "epoch:11\n",
      "loss:0.205334\n",
      "training acc: 0.13398437499999996\n",
      "training pr: 0.017423357338097224\n",
      "training re: 0.7407291666666665\n",
      "training fs: 0.03404581790085204\n",
      "training auc: 0.4479968644080178\n",
      "epoch:12\n",
      "loss:0.205302\n",
      "training acc: 0.12171617445054947\n",
      "training pr: 0.01745100609472307\n",
      "training re: 0.7527083333333334\n",
      "training fs: 0.034111155442548224\n",
      "training auc: 0.4431003919033426\n",
      "epoch:13\n",
      "loss:0.204868\n",
      "training acc: 0.1185267857142857\n",
      "training pr: 0.01753060044865344\n",
      "training re: 0.7590624999999998\n",
      "training fs: 0.03426970640113387\n",
      "training auc: 0.44510139996785875\n",
      "epoch:14\n",
      "loss:0.204555\n",
      "training acc: 0.1116844093406593\n",
      "training pr: 0.01755866474602868\n",
      "training re: 0.7663541666666664\n",
      "training fs: 0.03433072927122712\n",
      "training auc: 0.4470777908046985\n",
      "epoch:15\n",
      "loss:0.204159\n",
      "training acc: 0.10801854395604396\n",
      "training pr: 0.017645219169181554\n",
      "training re: 0.7735416666666665\n",
      "training fs: 0.03450336364547109\n",
      "training auc: 0.44919769386979896\n",
      "epoch:16\n",
      "loss:0.203993\n",
      "training acc: 0.1030541723901099\n",
      "training pr: 0.017715604845020442\n",
      "training re: 0.7811458333333331\n",
      "training fs: 0.03464547336926193\n",
      "training auc: 0.4476133159478729\n",
      "epoch:17\n",
      "loss:0.203786\n",
      "training acc: 0.09697372939560442\n",
      "training pr: 0.017762664730182075\n",
      "training re: 0.7887499999999998\n",
      "training fs: 0.034742906530629634\n",
      "training auc: 0.4479533733637213\n",
      "epoch:18\n",
      "loss:0.203682\n",
      "training acc: 0.09244720123626374\n",
      "training pr: 0.017769752996072533\n",
      "training re: 0.7931249999999996\n",
      "training fs: 0.03476068707813628\n",
      "training auc: 0.4469907721920288\n",
      "epoch:19\n",
      "loss:0.203445\n",
      "training acc: 0.0874184409340659\n",
      "training pr: 0.017923943943520707\n",
      "training re: 0.8047916666666668\n",
      "training fs: 0.03506688387725655\n",
      "training auc: 0.4463296498802011\n",
      "epoch:20\n",
      "loss:0.203212\n",
      "training acc: 0.08186383928571428\n",
      "training pr: 0.017934837990618662\n",
      "training re: 0.8103125\n",
      "training fs: 0.03509294671309923\n",
      "training auc: 0.44739411670172985\n",
      "epoch:21\n",
      "loss:0.202950\n",
      "training acc: 0.07872166895604396\n",
      "training pr: 0.01796735782855306\n",
      "training re: 0.8146875000000001\n",
      "training fs: 0.035159292040364325\n",
      "training auc: 0.44745311221657313\n",
      "epoch:22\n",
      "loss:0.202604\n",
      "training acc: 0.0748819539835165\n",
      "training pr: 0.01814269285479525\n",
      "training re: 0.8264583333333334\n",
      "training fs: 0.03550593658973374\n",
      "training auc: 0.4507943895365824\n",
      "epoch:23\n",
      "loss:0.202622\n",
      "training acc: 0.06938530219780217\n",
      "training pr: 0.018206370178746715\n",
      "training re: 0.8344791666666669\n",
      "training fs: 0.03563525270492222\n",
      "training auc: 0.44558276903634875\n",
      "epoch:24\n",
      "loss:0.202284\n",
      "training acc: 0.06632469093406591\n",
      "training pr: 0.018254304781410456\n",
      "training re: 0.8395833333333338\n",
      "training fs: 0.03573172051789212\n",
      "training auc: 0.45033834078424506\n",
      "epoch:25\n",
      "loss:0.202180\n",
      "training acc: 0.06360104739010991\n",
      "training pr: 0.018300272348766917\n",
      "training re: 0.844270833333334\n",
      "training fs: 0.035824022363909136\n",
      "training auc: 0.4488268101332397\n",
      "epoch:26\n",
      "loss:0.201888\n",
      "training acc: 0.059336366758241756\n",
      "training pr: 0.01850384513395204\n",
      "training re: 0.8580208333333335\n",
      "training fs: 0.03622643546692854\n",
      "training auc: 0.45094992731708733\n",
      "epoch:27\n",
      "loss:0.201697\n",
      "training acc: 0.05703125\n",
      "training pr: 0.01857768746344058\n",
      "training re: 0.8637499999999999\n",
      "training fs: 0.0363730518269149\n",
      "training auc: 0.45177601975222076\n",
      "epoch:28\n",
      "loss:0.201556\n",
      "training acc: 0.054279704670329686\n",
      "training pr: 0.018677331382788397\n",
      "training re: 0.8711458333333335\n",
      "training fs: 0.03657058606831155\n",
      "training auc: 0.451438884262506\n",
      "epoch:29\n",
      "loss:0.201435\n",
      "training acc: 0.05048935439560439\n",
      "training pr: 0.018773255687454263\n",
      "training re: 0.8793749999999998\n",
      "training fs: 0.036761703207886444\n",
      "training auc: 0.450823243557153\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "prediction_train = []\n",
    "for epoch in range(30):\n",
    "    print(\"epoch:\" + str(epoch))\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss=0\n",
    "    train_acc = 0\n",
    "    train_pr = 0\n",
    "    train_re = 0\n",
    "    train_fs = 0\n",
    "    train_auc = 0\n",
    "    for i, influ_mat in enumerate(inverse_pairs_train):\n",
    "        # print(i)\n",
    "        seed_vec = influ_mat[0]\n",
    "        # seed = torch.LongTensor(seed_vec).to(device)\n",
    "        influ_vec = influ_mat[1]\n",
    "        # print(influ_mat)\n",
    "        # print(influ_mat.shape)\n",
    "        # print(seed_vec)\n",
    "        # print(influ_vec)\n",
    "        V3 = copy.copy(influ_vec)\n",
    "        V4 = copy.copy(influ_vec)\n",
    "        \n",
    "        V3[influ_vec < 0.5] =  0.5 # play with this 0\n",
    "        V4[influ_vec >= 0.5] =  0.5 # 1\n",
    "        d1 = influ_vec\n",
    "        d1 = d1[:, np.newaxis]\n",
    "        d2 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), influ_vec)\n",
    "        d2 = d2[:, np.newaxis]\n",
    "        d3 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), V3)\n",
    "        d3 = d3[:, np.newaxis]\n",
    "        d4 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), V4)\n",
    "        d4 = d4[:, np.newaxis]\n",
    "        x = np.concatenate((d1, d2, d3, d4), axis=1)\n",
    "        x = torch.tensor(x,dtype=torch.float).to(device)\n",
    "        # seed_vec = torch.tensor(seed_vec).squeeze(-1).long().to(device)\n",
    "        seed_vec = seed_vec.clone().detach().requires_grad_(True).squeeze(-1).long().to(device)\n",
    "\n",
    "\n",
    "        # check github code\n",
    "        pred = model(x, edge_index)\n",
    "        # print(pred)\n",
    "\n",
    "        loss = criterion(pred, seed_vec)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # CHECK THE RANGE OF THIS TO RESET THRESHOLD\n",
    "        pred = torch.softmax(pred,dim=1)\n",
    "        pred = pred[:,1].squeeze(-1).cpu().detach().numpy()\n",
    "        # print(np.unique(pred))\n",
    "\n",
    "        train_auc += roc_auc_score(seed_vec, pred)\n",
    "\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i]>=threshold:\n",
    "                pred[i] = 1\n",
    "            else:\n",
    "                pred[i] = 0\n",
    "\n",
    "        train_acc += accuracy_score(seed_vec, pred)\n",
    "        train_pr += precision_score(seed_vec, pred , zero_division=0) # change to 0\n",
    "        train_re += recall_score(seed_vec, pred, zero_division=0)\n",
    "        train_fs += f1_score(seed_vec, pred, zero_division=0)\n",
    "\n",
    "\n",
    "        prediction_train.append(pred)\n",
    "    \n",
    "    print(\"loss:{:0.6f}\".format(total_loss/inverse_pairs_train.shape[0]))\n",
    "    print('training acc:', train_acc / inverse_pairs_train.shape[0])\n",
    "    print('training pr:', train_pr / inverse_pairs_train.shape[0])\n",
    "    print('training re:', train_re / inverse_pairs_train.shape[0])\n",
    "    print('training fs:', train_fs / inverse_pairs_train.shape[0])\n",
    "    print('training auc:', train_auc / inverse_pairs_train.shape[0])\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d09db6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32259.932728290558\n"
     ]
    }
   ],
   "source": [
    "print(end - begin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. testing of the entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c4090d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_threshold = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d1f5439f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0\n",
      "accuracy: 0.03811813186813187\n",
      "precision_score: 0.01912280701754386\n",
      "recall_score: 0.9083333333333333\n",
      "f1_score: 0.037457044673539525\n",
      "roc_auc_score: 0.46407199625993456\n",
      "i=1\n",
      "accuracy: 0.03743131868131868\n",
      "precision_score: 0.018771929824561405\n",
      "recall_score: 0.8916666666666667\n",
      "f1_score: 0.03676975945017182\n",
      "roc_auc_score: 0.45556334735857873\n",
      "i=2\n",
      "accuracy: 0.03743131868131868\n",
      "precision_score: 0.018771929824561405\n",
      "recall_score: 0.8916666666666667\n",
      "f1_score: 0.03676975945017182\n",
      "roc_auc_score: 0.45556334735857873\n",
      "i=3\n",
      "accuracy: 0.03708791208791209\n",
      "precision_score: 0.018596491228070177\n",
      "recall_score: 0.8833333333333333\n",
      "f1_score: 0.036426116838487975\n",
      "roc_auc_score: 0.45130902290790087\n",
      "i=4\n",
      "accuracy: 0.03914835164835165\n",
      "precision_score: 0.019649122807017545\n",
      "recall_score: 0.9333333333333333\n",
      "f1_score: 0.03848797250859106\n",
      "roc_auc_score: 0.4768349696119682\n",
      "i=5\n",
      "accuracy: 0.038461538461538464\n",
      "precision_score: 0.01929824561403509\n",
      "recall_score: 0.9166666666666666\n",
      "f1_score: 0.03780068728522337\n",
      "roc_auc_score: 0.4683263207106124\n",
      "i=6\n",
      "accuracy: 0.03743131868131868\n",
      "precision_score: 0.018771929824561405\n",
      "recall_score: 0.8916666666666667\n",
      "f1_score: 0.03676975945017182\n",
      "roc_auc_score: 0.45556334735857873\n",
      "i=7\n",
      "accuracy: 0.038461538461538464\n",
      "precision_score: 0.01929824561403509\n",
      "recall_score: 0.9166666666666666\n",
      "f1_score: 0.03780068728522337\n",
      "roc_auc_score: 0.4683263207106124\n",
      "i=8\n",
      "accuracy: 0.03708791208791209\n",
      "precision_score: 0.018596491228070177\n",
      "recall_score: 0.8833333333333333\n",
      "f1_score: 0.036426116838487975\n",
      "roc_auc_score: 0.45130902290790087\n",
      "i=9\n",
      "accuracy: 0.03571428571428571\n",
      "precision_score: 0.017894736842105262\n",
      "recall_score: 0.85\n",
      "f1_score: 0.03505154639175258\n",
      "roc_auc_score: 0.4342917251051893\n",
      "i=10\n",
      "accuracy: 0.03743131868131868\n",
      "precision_score: 0.018771929824561405\n",
      "recall_score: 0.8916666666666667\n",
      "f1_score: 0.03676975945017182\n",
      "roc_auc_score: 0.45556334735857873\n",
      "i=11\n",
      "accuracy: 0.03708791208791209\n",
      "precision_score: 0.018596491228070177\n",
      "recall_score: 0.8833333333333333\n",
      "f1_score: 0.036426116838487975\n",
      "roc_auc_score: 0.45130902290790087\n",
      "i=12\n",
      "accuracy: 0.036744505494505496\n",
      "precision_score: 0.018421052631578946\n",
      "recall_score: 0.875\n",
      "f1_score: 0.03608247422680412\n",
      "roc_auc_score: 0.447054698457223\n",
      "i=13\n",
      "accuracy: 0.03811813186813187\n",
      "precision_score: 0.01912280701754386\n",
      "recall_score: 0.9083333333333333\n",
      "f1_score: 0.037457044673539525\n",
      "roc_auc_score: 0.46407199625993456\n",
      "i=14\n",
      "accuracy: 0.038461538461538464\n",
      "precision_score: 0.01929824561403509\n",
      "recall_score: 0.9166666666666666\n",
      "f1_score: 0.03780068728522337\n",
      "roc_auc_score: 0.4683263207106124\n",
      "i=15\n",
      "accuracy: 0.03914835164835165\n",
      "precision_score: 0.019649122807017545\n",
      "recall_score: 0.9333333333333333\n",
      "f1_score: 0.03848797250859106\n",
      "roc_auc_score: 0.4768349696119682\n",
      "i=16\n",
      "accuracy: 0.03811813186813187\n",
      "precision_score: 0.01912280701754386\n",
      "recall_score: 0.9083333333333333\n",
      "f1_score: 0.037457044673539525\n",
      "roc_auc_score: 0.46407199625993456\n",
      "i=17\n",
      "accuracy: 0.038461538461538464\n",
      "precision_score: 0.01929824561403509\n",
      "recall_score: 0.9166666666666666\n",
      "f1_score: 0.03780068728522337\n",
      "roc_auc_score: 0.4683263207106124\n",
      "i=18\n",
      "accuracy: 0.036744505494505496\n",
      "precision_score: 0.018421052631578946\n",
      "recall_score: 0.875\n",
      "f1_score: 0.03608247422680412\n",
      "roc_auc_score: 0.447054698457223\n",
      "i=19\n",
      "accuracy: 0.03949175824175824\n",
      "precision_score: 0.019824561403508772\n",
      "recall_score: 0.9416666666666667\n",
      "f1_score: 0.038831615120274915\n",
      "roc_auc_score: 0.4810892940626461\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_pr = 0\n",
    "test_re = 0\n",
    "test_fs = 0\n",
    "test_auc = 0\n",
    "\n",
    "\n",
    "num_node = adj.shape[0]\n",
    "# setting the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for i, influ_mat in enumerate(inverse_pairs_test):\n",
    "    print(\"i={:d}\".format(i))\n",
    "    seed_vec = influ_mat[0]\n",
    "    influ_vec = influ_mat[1]\n",
    "    V3 = copy.copy(influ_vec)\n",
    "    V4 = copy.copy(influ_vec)\n",
    "    V3[influ_vec < 0.5] =  0.5\n",
    "    V4[influ_vec >= 0.5] =  0.5\n",
    "    d1 = influ_vec\n",
    "    d1 = d1[:, np.newaxis]\n",
    "    d2 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), influ_vec)\n",
    "    d2 = d2[:, np.newaxis]\n",
    "    d3 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), V3)\n",
    "    d3 = d3[:, np.newaxis]\n",
    "    d4 = (1 - alpha) * np.matmul(np.linalg.inv(np.eye(N=num_node) - alpha * S), V4)\n",
    "    d4 = d4[:, np.newaxis]\n",
    "    x = np.concatenate((d1, d2, d3, d4), axis=1)\n",
    "    x = torch.tensor(x,dtype=torch.float).to(device)\n",
    "    # seed_vec = torch.tensor(seed_vec).squeeze(-1).long().to(device)\n",
    "    seed_vec = seed_vec.clone().detach().requires_grad_(True).squeeze(-1).long().to(device)\n",
    "\n",
    "    pred = model(x, edge_index)\n",
    "    pred = torch.softmax(pred,dim=1)\n",
    "    pred = pred[:,1].squeeze(-1).cpu().detach().numpy()\n",
    "\n",
    "    test_auc += roc_auc_score(seed_vec, pred )\n",
    "        \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]>=testing_threshold:\n",
    "            pred[i] = 1\n",
    "        else:\n",
    "            pred[i] = 0\n",
    "\n",
    "    print(\"accuracy: \" + str(accuracy_score(seed_vec, pred)))\n",
    "    print(\"precision_score: \" + str(precision_score(seed_vec, pred, zero_division=0)))\n",
    "    print(\"recall_score: \" + str(recall_score(seed_vec, pred , zero_division=0)))\n",
    "    print(\"f1_score: \" + str(f1_score(seed_vec, pred , zero_division=0)))\n",
    "    print(\"roc_auc_score: \" + str(roc_auc_score(seed_vec, pred)))\n",
    "\n",
    "    test_acc += accuracy_score(seed_vec, pred)\n",
    "    test_pr += precision_score(seed_vec, pred , zero_division=0)\n",
    "    test_re += recall_score(seed_vec, pred , zero_division=0)\n",
    "    test_fs += f1_score(seed_vec, pred , zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b724d849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.08100961538461537\n",
      "test pr: 0.013193152214365464\n",
      "test re: 0.5908333333333333\n",
      "test fs: 0.02580997451765562\n",
      "test auc: 0.4309856752571296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('test acc:', test_acc / inverse_pairs_test.shape[0])\n",
    "print('test pr:', test_pr / inverse_pairs_test.shape[0])\n",
    "print('test re:', test_re / inverse_pairs_test.shape[0])\n",
    "print('test fs:', test_fs / inverse_pairs_test.shape[0])\n",
    "print('test auc:', test_auc / inverse_pairs_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbb427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
